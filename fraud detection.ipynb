{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "train_identity = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\n",
    "#print(train_identity['TransactionID'].size, train_identity['TransactionID'].unique().size)\n",
    "#print(train_identity.loc[:, train_identity.isnull().any()])\n",
    "    \n",
    "#print(train_identity['id_17'].value_counts())\n",
    "#for col in train_identity.loc[:, train_identity.isnull().any()].columns:\n",
    "#    print(train_identity[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\n",
    "#print(train_transaction['TransactionID'].size, train_transaction['TransactionID'].unique().size)\n",
    "#print(train_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_identity, train_transaction], axis=1)\n",
    "#print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_identity = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transaction = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test_identity, test_transaction], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*chunks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chunk = train#.sample(frac=0.05, random_state=1)\n",
    "y_chunk = train_chunk['isFraud']\n",
    "train_chunk.drop(['isFraud'], axis=1, inplace=True)\n",
    "y_chunk.value_counts()\n",
    "\n",
    "train = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_chunk.loc[:, train_chunk.isnull().any()].columns:\n",
    "    #print(col)\n",
    "    vc = train_chunk[col].value_counts(dropna=False, normalize=True)\n",
    "    if vc.loc[np.nan] > 0.9:\n",
    "        nan_cols.add(col)\n",
    "\n",
    "#train_chunk['id_12'].value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nan_cols)#, nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test.loc[:, test.isnull().any()].columns:\n",
    "    #print(col)\n",
    "    vc = test[col].value_counts(dropna=False, normalize=True)\n",
    "    if vc.loc[np.nan] > 0.9:\n",
    "        nan_cols.add(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nan_cols)#, nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_cols = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_chunk.columns:\n",
    "    #print(col)\n",
    "    vc = train_chunk[col].value_counts(normalize=True)\n",
    "    if vc[vc.index[0]] > 0.9:\n",
    "        #print(col)\n",
    "        #print(vc.index[0], vc[vc.index[0]])\n",
    "        one_value_cols.add(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(one_value_cols)#, one_value_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test.columns:\n",
    "    #print(col)\n",
    "    vc = test[col].value_counts(normalize=True)\n",
    "    if vc[vc.index[0]] > 0.9:\n",
    "        #print(col)\n",
    "        #print(vc.index[0], vc[vc.index[0]])\n",
    "        one_value_cols.add(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(one_value_cols)#, one_value_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_this = list(nan_cols.union(one_value_cols))\n",
    "len(drop_this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*concatenate train+test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_chunk, test], sort=False)\n",
    "data.drop(drop_this, axis=1, inplace=True)\n",
    "size = train_chunk.shape[0]\n",
    "train_chunk = 0\n",
    "test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id30(x):\n",
    "    if pd.isnull(x):\n",
    "        return x    \n",
    "    elif 'windows' in x.lower():\n",
    "        return 'Windows'\n",
    "    elif 'ios' in x.lower():\n",
    "        return 'iOS'\n",
    "    elif 'mac' in x.lower():\n",
    "        return 'Mac OS'\n",
    "    elif 'android' in x.lower():\n",
    "        return 'Android'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "data['id_30'] = data['id_30'].apply(id30)\n",
    "data['id_30'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id31(x):    \n",
    "    if pd.isnull(x):\n",
    "        return x\n",
    "    elif 'chrome' in x.lower():\n",
    "        return 'Chrome' \n",
    "    elif 'safari' in x.lower():\n",
    "        return 'Safari'\n",
    "    elif 'firefox' in x.lower():\n",
    "        return 'Firefox'\n",
    "    elif 'ie' in x.lower():\n",
    "        return 'Internet Explorer'\n",
    "    elif 'edge' in x.lower():\n",
    "        return 'Microsoft Edge'\n",
    "    elif 'samsung' in x.lower():\n",
    "        return 'Samsung Browser'\n",
    "    elif 'google' in x.lower():\n",
    "        return 'Google Search Application'\n",
    "    elif 'opera' in x.lower():\n",
    "        return 'Opera'\n",
    "    elif 'android' in x.lower():\n",
    "        return 'Android Browser'\n",
    "    elif 'facebook' in x.lower():\n",
    "        return 'Facebook'    \n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "data['id_31'] = data['id_31'].apply(id31)\n",
    "data['id_31'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id_33_hor'] = data['id_33'].apply(lambda x: x if pd.isnull(x) else x.split('x')[0])\n",
    "data['id_33_vert'] = data['id_33'].apply(lambda x: x if pd.isnull(x) else x.split('x')[1])\n",
    "data.drop(['id_33'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devinfo(x):\n",
    "    if pd.isnull(x):\n",
    "        return x    \n",
    "    elif 'rv:' in x.lower():\n",
    "        return 'rv'\n",
    "    elif 'sm-' in x.lower():\n",
    "        return 'SM'\n",
    "    elif 'moto' in x.lower():\n",
    "        return 'Moto'\n",
    "    elif ('huawei' in x.lower()) or ('-l' in x.lower()):\n",
    "        return 'HUAWEI'\n",
    "    elif 'lg-' in x.lower():\n",
    "        return 'LG'\n",
    "    elif 'pixel' in x.lower():\n",
    "        return 'Pixel'\n",
    "    elif 'samsung' in x.lower():\n",
    "        return 'Samsung'\n",
    "    elif 'windows' in x.lower():\n",
    "        return 'Windows'\n",
    "    elif ('ios device' in x.lower()) or ('macos' in x.lower()) or ('trident' in x.lower()):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "data['DeviceInfo'] = data['DeviceInfo'].apply(devinfo)\n",
    "data['DeviceInfo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_email(x):\n",
    "    if pd.isnull(x):\n",
    "        return x    \n",
    "    elif 'gmail' in x:\n",
    "        return 'gmail'\n",
    "    if 'yahoo' in x:\n",
    "        return 'yahoo'\n",
    "    if 'hotmail' in x:\n",
    "        return 'hotmail'\n",
    "    if 'outlook' in x:\n",
    "        return 'outlook'\n",
    "    if 'anonymous' in x:\n",
    "        return 'anonymous'\n",
    "    if 'aol' in x:\n",
    "        return 'aol'\n",
    "    if 'comcast' in x:\n",
    "        return 'comcast'\n",
    "    if 'icloud' in x:\n",
    "        return 'icloud'\n",
    "    if 'live' in x:\n",
    "        return 'live'\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "data['P_emaildomain'] = data['P_emaildomain'].apply(p_email)\n",
    "data['P_emaildomain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['R_emaildomain'] = data['R_emaildomain'].apply(p_email)\n",
    "data['R_emaildomain'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "**Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(df):\n",
    "    for label, col in df.loc[:, df.isnull().any()].iteritems():    \n",
    "        missing = df[label].isnull()\n",
    "        vc = col.value_counts(normalize=True)    \n",
    "        df.loc[missing, label] = np.random.choice(vc.index, size=col.size-col.count(), p=vc.values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train['id_01'].value_counts())\n",
    "#train_copy = train\n",
    "#missing_values(train_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_copy = test\n",
    "#missing_values(test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*dummies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*scaling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "\n",
    "data = scale(data)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_final.shape)\n",
    "print(test_final.shape)\n",
    "scaled_test = scaler.transform(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = data[:size]\n",
    "test_final = data[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_final.to_csv('train_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_final.to_csv('test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.power(10.0, np.arange(-5, 6)):\n",
    "    print('C={}'.format(c))\n",
    "    print('Score {}\\n'.format(cross_val_score(LogisticRegression(C=c, solver='lbfgs', max_iter=300), scaled_train, y_chunk, cv=cv, scoring='roc_auc').mean()))\n",
    "    \n",
    "#best_logreg = 'C=0.001, Score 0.792172393105506'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_svc = [0, 0, 0]\n",
    "for c in np.power(10.0, np.arange(-5, 6)):\n",
    "    for g in np.power(10.0, np.arange(-5, 6)):\n",
    "        print('C={}, gamma={}'.format(c, g))\n",
    "        svc_score = cross_val_score(SVC(C=c, gamma=g), scaled_train, y_chunk, cv=cv, scoring='roc_auc').mean()\n",
    "        print('Score {}\\n'.format(svc_score))\n",
    "        if svc_score > best_svc[2]:\n",
    "            best_svc = [c, g, svc_score]\n",
    "            \n",
    "print('C={}, gamma={}, Score {}'.format(best_svc[0], best_svc[1], best_svc[2]))\n",
    "#best_svc = 'C=0.1, gamma=0.001, Score 0.7483778558809864'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "rf_score = []\n",
    "n = [50, 100, 150, 200]\n",
    "for k in n:\n",
    "    print('K={}'.format(k))\n",
    "    rf_score.append(cross_val_score(RandomForestClassifier(n_estimators=k, random_state=1), train_final, y_chunk, cv=cv, scoring='roc_auc').mean())\n",
    "    print('Score {}\\n'.format(rf_score[-1]))\n",
    "    \n",
    "estim = n[np.argmax(rf_score)] #0.8456387249804596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb_score = []\n",
    "n = [100, 125, 150, 175, 200]\n",
    "lrate = [0.1, 0.05, 0.01]\n",
    "for k in n:\n",
    "    for l in lrate:\n",
    "        print('K={}, Learning rate = {}'.format(k, l))\n",
    "        gb_score.append(cross_val_score(GradientBoostingClassifier(n_estimators=k, learning_rate=l, random_state=1), train_final, y_chunk, cv=cv, scoring='roc_auc').mean())\n",
    "        print('Score {}\\n'.format(gb_score[-1]))\n",
    "        \n",
    "#best_gb = 'K=125, Learning rate = 0.1, Score 0.8395876357222953'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.lineplot(n, rf_score)\n",
    "#sns.lineplot(lrate, gb_score[:3], label='100')\n",
    "#sns.lineplot(lrate, gb_score[3:6], label='125')\n",
    "#sns.lineplot(lrate, gb_score[6:9], label='150')\n",
    "#sns.lineplot(lrate, gb_score[9:12], label='175')\n",
    "#sns.lineplot(lrate, gb_score[12:], label='200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "#cls = RandomForestClassifier(n_estimators=estim, random_state=1)\n",
    "cls = GradientBoostingClassifier(n_estimators=200, random_state=1)\n",
    "cls.fit(train_final, y_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['isFraud'] = cls.predict_proba(test_final)[:, 1]\n",
    "#submission['isFraud']\n",
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
