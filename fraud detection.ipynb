{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "train_identity = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\n",
    "#print(train_identity['TransactionID'].size, train_identity['TransactionID'].unique().size)\n",
    "#print(train_identity.loc[:, train_identity.isnull().any()])\n",
    "    \n",
    "#print(train_identity['id_17'].value_counts())\n",
    "#for col in train_identity.loc[:, train_identity.isnull().any()].columns:\n",
    "#    print(train_identity[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_transaction = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\n",
    "#print(train_transaction['TransactionID'].size, train_transaction['TransactionID'].unique().size)\n",
    "#print(train_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([train_identity, train_transaction], axis=1)\n",
    "#print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_identity = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_transaction = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "test = pd.concat([test_identity, test_transaction], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*chunks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chunk = train#.sample(frac=0.05, random_state=1)\n",
    "y_chunk = train_chunk['isFraud']\n",
    "train_chunk.drop(['isFraud'], axis=1, inplace=True)\n",
    "y_chunk.value_counts()\n",
    "\n",
    "train = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_chunk.loc[:, train_chunk.isnull().any()].columns:\n",
    "    #print(col)\n",
    "    vc = train_chunk[col].value_counts(dropna=False, normalize=True)\n",
    "    if vc.loc[np.nan] > 0.9:\n",
    "        nan_cols.add(col)\n",
    "\n",
    "#train_chunk['id_12'].value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nan_cols)#, nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test.loc[:, test.isnull().any()].columns:\n",
    "    #print(col)\n",
    "    vc = test[col].value_counts(dropna=False, normalize=True)\n",
    "    if vc.loc[np.nan] > 0.9:\n",
    "        nan_cols.add(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nan_cols)#, nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_cols = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_chunk.columns:\n",
    "    #print(col)\n",
    "    vc = train_chunk[col].value_counts(normalize=True)\n",
    "    if vc[vc.index[0]] > 0.9:\n",
    "        #print(col)\n",
    "        #print(vc.index[0], vc[vc.index[0]])\n",
    "        one_value_cols.add(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_value_cols)#, one_value_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test.columns:\n",
    "    #print(col)\n",
    "    vc = test[col].value_counts(normalize=True)\n",
    "    if vc[vc.index[0]] > 0.9:\n",
    "        #print(col)\n",
    "        #print(vc.index[0], vc[vc.index[0]])\n",
    "        one_value_cols.add(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_value_cols)#, one_value_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_this = list(nan_cols.union(one_value_cols))\n",
    "len(drop_this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*concatenate train+test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_chunk, test], sort=False)\n",
    "data.drop(drop_this, axis=1, inplace=True)\n",
    "size = train_chunk.shape[0]\n",
    "train_chunk = 0\n",
    "test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Windows    69777\n",
       "iOS        38502\n",
       "Mac OS     25634\n",
       "Android    11783\n",
       "Linux       2488\n",
       "func          21\n",
       "other         19\n",
       "Name: id_30, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def id30(x):\n",
    "    if pd.isnull(x):\n",
    "        return x    \n",
    "    elif 'windows' in x.lower():\n",
    "        return 'Windows'\n",
    "    elif 'ios' in x.lower():\n",
    "        return 'iOS'\n",
    "    elif 'mac' in x.lower():\n",
    "        return 'Mac OS'\n",
    "    elif 'android' in x.lower():\n",
    "        return 'Android'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "data['id_30'] = data['id_30'].apply(id30)\n",
    "data['id_30'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chrome                       155502\n",
       "Safari                        69866\n",
       "Internet Explorer             16372\n",
       "Firefox                       14393\n",
       "Microsoft Edge                11985\n",
       "Samsung Browser                4787\n",
       "Google Search Application      2146\n",
       "Opera                           843\n",
       "other                           470\n",
       "Android Browser                 420\n",
       "Facebook                        123\n",
       "Name: id_31, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def id31(x):    \n",
    "    if pd.isnull(x):\n",
    "        return x\n",
    "    elif 'chrome' in x.lower():\n",
    "        return 'Chrome' \n",
    "    elif 'safari' in x.lower():\n",
    "        return 'Safari'\n",
    "    elif 'firefox' in x.lower():\n",
    "        return 'Firefox'\n",
    "    elif 'ie' in x.lower():\n",
    "        return 'Internet Explorer'\n",
    "    elif 'edge' in x.lower():\n",
    "        return 'Microsoft Edge'\n",
    "    elif 'samsung' in x.lower():\n",
    "        return 'Samsung Browser'\n",
    "    elif 'google' in x.lower():\n",
    "        return 'Google Search Application'\n",
    "    elif 'opera' in x.lower():\n",
    "        return 'Opera'\n",
    "    elif 'android' in x.lower():\n",
    "        return 'Android Browser'\n",
    "    elif 'facebook' in x.lower():\n",
    "        return 'Facebook'    \n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "data['id_31'] = data['id_31'].apply(id31)\n",
    "data['id_31'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id_33_hor'] = data['id_33'].apply(lambda x: x if pd.isnull(x) else x.split('x')[0])\n",
    "data['id_33_vert'] = data['id_33'].apply(lambda x: x if pd.isnull(x) else x.split('x')[1])\n",
    "data.drop(['id_33'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Windows        92763\n",
       "iOS Device     38502\n",
       "SM             24583\n",
       "MacOS          23722\n",
       "other          14132\n",
       "Trident/7.0    12330\n",
       "Moto            8155\n",
       "rv              7197\n",
       "HUAWEI          7004\n",
       "LG              4289\n",
       "Pixel            582\n",
       "Samsung          464\n",
       "Name: DeviceInfo, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def devinfo(x):\n",
    "    if pd.isnull(x):\n",
    "        return x    \n",
    "    elif 'rv:' in x.lower():\n",
    "        return 'rv'\n",
    "    elif 'sm-' in x.lower():\n",
    "        return 'SM'\n",
    "    elif 'moto' in x.lower():\n",
    "        return 'Moto'\n",
    "    elif ('huawei' in x.lower()) or ('-l' in x.lower()):\n",
    "        return 'HUAWEI'\n",
    "    elif 'lg-' in x.lower():\n",
    "        return 'LG'\n",
    "    elif 'pixel' in x.lower():\n",
    "        return 'Pixel'\n",
    "    elif 'samsung' in x.lower():\n",
    "        return 'Samsung'\n",
    "    elif 'windows' in x.lower():\n",
    "        return 'Windows'\n",
    "    elif ('ios device' in x.lower()) or ('macos' in x.lower()) or ('trident' in x.lower()):\n",
    "        return x\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "data['DeviceInfo'] = data['DeviceInfo'].apply(devinfo)\n",
    "data['DeviceInfo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmail        436796\n",
       "yahoo        186568\n",
       "hotmail       87414\n",
       "anonymous     71062\n",
       "other         54523\n",
       "aol           52337\n",
       "comcast       14474\n",
       "icloud        12316\n",
       "outlook       10797\n",
       "live           7296\n",
       "Name: P_emaildomain, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def p_email(x):\n",
    "    if pd.isnull(x):\n",
    "        return x    \n",
    "    elif 'gmail' in x:\n",
    "        return 'gmail'\n",
    "    if 'yahoo' in x:\n",
    "        return 'yahoo'\n",
    "    if 'hotmail' in x:\n",
    "        return 'hotmail'\n",
    "    if 'outlook' in x:\n",
    "        return 'outlook'\n",
    "    if 'anonymous' in x:\n",
    "        return 'anonymous'\n",
    "    if 'aol' in x:\n",
    "        return 'aol'\n",
    "    if 'comcast' in x:\n",
    "        return 'comcast'\n",
    "    if 'icloud' in x:\n",
    "        return 'icloud'\n",
    "    if 'live' in x:\n",
    "        return 'live'\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "data['P_emaildomain'] = data['P_emaildomain'].apply(p_email)\n",
    "data['P_emaildomain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmail        119081\n",
       "hotmail       54875\n",
       "anonymous     39644\n",
       "yahoo         24912\n",
       "other         12200\n",
       "aol            7239\n",
       "outlook        5864\n",
       "comcast        3513\n",
       "live           3013\n",
       "icloud         2820\n",
       "Name: R_emaildomain, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['R_emaildomain'] = data['R_emaildomain'].apply(p_email)\n",
    "data['R_emaildomain'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "**Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(df):\n",
    "    for label, col in df.loc[:, df.isnull().any()].iteritems():    \n",
    "        missing = df[label].isnull()\n",
    "        vc = col.value_counts(normalize=True)    \n",
    "        df.loc[missing, label] = np.random.choice(vc.index, size=col.size-col.count(), p=vc.values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train['id_01'].value_counts())\n",
    "#train_copy = train\n",
    "#missing_values(train_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_copy = test\n",
    "#missing_values(test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*dummies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097231, 801)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*scaling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = scale(data)\\n\\nscaler = StandardScaler()\\nscaled_train = scaler.fit_transform(train_final)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "\n",
    "data = scale(data)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(train_final.shape)\\nprint(test_final.shape)\\nscaled_test = scaler.transform(test_final)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_final.shape)\n",
    "print(test_final.shape)\n",
    "scaled_test = scaler.transform(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = data[:size]\n",
    "test_final = data[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_final.to_csv('train_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_final.to_csv('test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor c in np.power(10.0, np.arange(-5, 6)):\\n    print('C={}'.format(c))\\n    print('Score {}\\n'.format(cross_val_score(LogisticRegression(C=c, solver='lbfgs', max_iter=300), scaled_train, y_chunk, cv=cv, scoring='roc_auc').mean()))\\n    \\nbest_logreg = 'C=0.001, Score 0.792172393105506'\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in np.power(10.0, np.arange(-5, 6)):\n",
    "    print('C={}'.format(c))\n",
    "    print('Score {}\\n'.format(cross_val_score(LogisticRegression(C=c, solver='lbfgs', max_iter=300), scaled_train, y_chunk, cv=cv, scoring='roc_auc').mean()))\n",
    "    \n",
    "#best_logreg = 'C=0.001, Score 0.792172393105506'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbest_svc = [0, 0, 0]\\nfor c in np.power(10.0, np.arange(-5, 6)):\\n    for g in np.power(10.0, np.arange(-5, 6)):\\n        print('C={}, gamma={}'.format(c, g))\\n        svc_score = cross_val_score(SVC(C=c, gamma=g), scaled_train, y_chunk, cv=cv, scoring='roc_auc').mean()\\n        print('Score {}\\n'.format(svc_score))\\n        if svc_score > best_svc[2]:\\n            best_svc = [c, g, svc_score]\\n            \\nprint('C={}, gamma={}, Score {}'.format(best_svc[0], best_svc[1], best_svc[2]))\\nbest_svc = 'C=0.1, gamma=0.001, Score 0.7483778558809864'\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_svc = [0, 0, 0]\n",
    "for c in np.power(10.0, np.arange(-5, 6)):\n",
    "    for g in np.power(10.0, np.arange(-5, 6)):\n",
    "        print('C={}, gamma={}'.format(c, g))\n",
    "        svc_score = cross_val_score(SVC(C=c, gamma=g), scaled_train, y_chunk, cv=cv, scoring='roc_auc').mean()\n",
    "        print('Score {}\\n'.format(svc_score))\n",
    "        if svc_score > best_svc[2]:\n",
    "            best_svc = [c, g, svc_score]\n",
    "            \n",
    "print('C={}, gamma={}, Score {}'.format(best_svc[0], best_svc[1], best_svc[2]))\n",
    "#best_svc = 'C=0.1, gamma=0.001, Score 0.7483778558809864'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrf_score = []\\nn = [50, 100, 150, 200]\\nfor k in n:\\n    print('K={}'.format(k))\\n    rf_score.append(cross_val_score(RandomForestClassifier(n_estimators=k, random_state=1), train_final, y_chunk, cv=cv, scoring='roc_auc').mean())\\n    print('Score {}\\n'.format(rf_score[-1]))\\n    \\nestim = n[np.argmax(rf_score)] #0.8456387249804596\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "rf_score = []\n",
    "n = [50, 100, 150, 200]\n",
    "for k in n:\n",
    "    print('K={}'.format(k))\n",
    "    rf_score.append(cross_val_score(RandomForestClassifier(n_estimators=k, random_state=1), train_final, y_chunk, cv=cv, scoring='roc_auc').mean())\n",
    "    print('Score {}\\n'.format(rf_score[-1]))\n",
    "    \n",
    "estim = n[np.argmax(rf_score)] #0.8456387249804596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ngb_score = []\\nn = [100, 125, 150, 175, 200]\\nlrate = [0.1, 0.05, 0.01]\\nfor k in n:\\n    for l in lrate:\\n        print('K={}, Learning rate = {}'.format(k, l))\\n        gb_score.append(cross_val_score(GradientBoostingClassifier(n_estimators=k, learning_rate=l, random_state=1), train_final, y_chunk, cv=cv, scoring='roc_auc').mean())\\n        print('Score {}\\n'.format(gb_score[-1]))\\n        \\nbest_gb = 'K=125, Learning rate = 0.1, Score 0.8395876357222953'\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gb_score = []\n",
    "n = [100, 125, 150, 175, 200]\n",
    "lrate = [0.1, 0.05, 0.01]\n",
    "for k in n:\n",
    "    for l in lrate:\n",
    "        print('K={}, Learning rate = {}'.format(k, l))\n",
    "        gb_score.append(cross_val_score(GradientBoostingClassifier(n_estimators=k, learning_rate=l, random_state=1), train_final, y_chunk, cv=cv, scoring='roc_auc').mean())\n",
    "        print('Score {}\\n'.format(gb_score[-1]))\n",
    "        \n",
    "#best_gb = 'K=125, Learning rate = 0.1, Score 0.8395876357222953'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-965dfb22a6a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#sns.lineplot(lrate, gb_score[:3], label='100')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#sns.lineplot(lrate, gb_score[3:6], label='125')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.lineplot(n, rf_score)\n",
    "#sns.lineplot(lrate, gb_score[:3], label='100')\n",
    "#sns.lineplot(lrate, gb_score[3:6], label='125')\n",
    "#sns.lineplot(lrate, gb_score[6:9], label='150')\n",
    "#sns.lineplot(lrate, gb_score[9:12], label='175')\n",
    "#sns.lineplot(lrate, gb_score[12:], label='200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=1, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "#cls = RandomForestClassifier(n_estimators=estim, random_state=1)\n",
    "cls = GradientBoostingClassifier(n_estimators=200, random_state=1)\n",
    "cls.fit(train_final, y_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['isFraud'] = cls.predict_proba(test_final)[:, 1]\n",
    "#submission['isFraud']\n",
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
